{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python提供了`__future__`模块，把下一个新版本的特性导入到当前版本，于是我们就可以在当前版本中测试一些新版本的特性。  \n",
    "`re`是正则表达式模块  \n",
    "`torch.optim`是为了更方便的更新\n",
    "这个网址 https://blog.csdn.net/stupid_3/article/details/83184691 和B站李宏毅的课程讲的比较清楚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 0, \"EOS\": 1}\n",
    "        self.word2count = {\"SOS\": 0, \"EOS\": 0, \"NNNN\": 0}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS and NNNN\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "MAX_LEN = 12\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def standardizeSeq(s):\n",
    "    return \"SOS \" + s + \" EOS\"\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    #这个是前面不补SOS，后面不补EOS，也不补助的情况。\n",
    "    #return [pair for pair in pairs if filterPair(pair)]\n",
    "    #这个是补了SOS，EOS，且长度补齐的情况\n",
    "    return [(standardizeSeq(pair[0]), standardizeSeq(pair[1])) for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "('SOS c est lui n est ce pas ? EOS', 'SOS he s the one isn t he ? EOS')\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各个变量的维度：（这个和下面的矩阵横竖是一样的，第一维是横，一般输入也是第一维是长度嘛，然后竖着表示特征数）  \n",
    "input: len \\* input_size(特征数）  \n",
    "output: len \\* input_size(特征数)  \n",
    "matq: len \\* hidden_size  \n",
    "matv: 同上  \n",
    "matk: 同上  \n",
    "scale:  那个就是指 $\\sqrt{output\\_size}$ ，除以就是减小结果  \n",
    "然后是我的代码中的:  \n",
    "attention: 与论文中的不一样，就是q,v产生的，len \\* len  \n",
    "mattv: 这个是论文中的attention, len \\* hidden_size  \n",
    "y: len \\* input_size\n",
    "首先我们要明白self-attention是什么，其实它输入输出和RNN是一样的，就是用于替换RNN层  \n",
    "各个变量的现实意义：  \n",
    "个人理解：q表示询问，可以理解当前这个元素的信息，而k则是key，可以理解为询问对这个问题产生的关注是多少，将这个元素和某个元素组合，得到attention，v则是值，表示当前元素的值，用于经过这样的attention,最后产生的影响\n",
    "![avatar](self-attention1.jpg)\n",
    "然后我们可以把向量叠成matrix来简化运算,其中q,k,v都是input通过矩阵乘法产生的\n",
    "![avatar](matrix1.jpg) ![avatar](matrix2.jpg)\n",
    "首先理解scaledDotProductAttention是在干什么：  \n",
    "![avatar](scaled_dot-product_attention.jpg)  \n",
    "scaledDotAttention就是在干这个，之所以可以写成矩阵乘法就是如同上面的那个图，下面贴一个完整的图：\n",
    "![avatar](sdpa.jpg)\n",
    "其中的那个scale就是前面说的除以减小结果的意思  \n",
    "而mask就是为了不再不必要的地方产生attention，比如为了使句子长度相同而后补的0，比如在decoder时输出时不应看到未来的，例如现在在句中的位置t，\n",
    "就应仅与句子中的t-1前的内容产生attention。而mask的方法就是在那些位置填-inf,这样softmax后就变成0了。下面的`tensor.mask_fill_(bool_matrix,value)`  \n",
    "下面是multiheadAttention  \n",
    "![avatar](mha.jpg)\n",
    "concat就是把几个head拼接起来，h是head的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意linear是这样瞎搞的，它的输入也是第一维是长度，和前面是对应的，中间随你放多少维，反正最后一维是特征数\n",
    "![avatar](linear.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, head = 2):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_dim = hidden_size // head\n",
    "        self.input_size = input_size\n",
    "        self.head = head\n",
    "        \n",
    "        self.qlinear = nn.Linear(input_size,hidden_size)\n",
    "        self.vlinear = nn.Linear(input_size,hidden_size)\n",
    "        self.klinear = nn.Linear(input_size,hidden_size)\n",
    "        self.ylinear = nn.Linear(hidden_size,input_size)\n",
    "        \n",
    "    def scaledDotProductAttention(self, matq, matk, matv, mask):\n",
    "        scale = matk.size(-1)**0.5\n",
    "        matt = matq.matmul(matk.transpose(1,2))/scale  #(head, N, hidden_dim) * (head, hidden_dim, N) -> (head, N, N)\n",
    "        if not mask is None:\n",
    "            matt.masked_fill_(mask, -np.inf)\n",
    "        matt = F.softmax(matt, dim=-1)  #(head, N, N) * (head, N, hidde_dim)\n",
    "        mattv = matt.matmul(matv)\n",
    "        return torch.cat(torch.chunk(mattv.view(-1,self.hidden_dim), self.head,0), dim = 1) #(head, N, hidden_dim) ->(N, hidden_size)\n",
    "    \n",
    "    def toMulti(self, matx):#这里是把特征等分\n",
    "        return torch.cat(torch.chunk(matx, self.head, -1),dim=0).view(self.head, -1, self.hidden_dim)\n",
    "    \n",
    "    def forward(self, inputq, inputk, inputv, mask = None):\n",
    "        matq = self.toMulti(self.qlinear(inputq))\n",
    "        matv = self.toMulti(self.vlinear(inputv))\n",
    "        matk = self.toMulti(self.klinear(inputk))\n",
    "        mattv = self.scaledDotProductAttention(matq, matk, matv, mask)\n",
    "        y = self.ylinear(mattv)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequece_mask(input):\n",
    "    len = input.size(-2)\n",
    "    return torch.triu(torch.ones((len,len), dtype = torch.bool), diagonal = 1).to(device)\n",
    "    #里面ones和zeros差不多，就是产生1； dtype之所以用这个是因为mask需要为bool\n",
    "    #而triu函数则是将参数一的上三角部分返回回去，剩下的补0，而diagonal决定了是否多返回或少返回，看下面这张图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](triu.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9800,  0.9045,  0.5975,  0.2966,  0.8535],\n",
      "        [-1.1063,  1.0337,  0.5560,  0.4519,  0.9150],\n",
      "        [-1.0342,  0.9600,  0.5809,  0.3624,  0.8811],\n",
      "        [-0.9960,  0.9172,  0.5353,  0.3530,  0.8082],\n",
      "        [-0.7773,  0.7095,  0.8539, -0.0749,  0.9318],\n",
      "        [-1.0151,  0.9433,  0.6298,  0.3115,  0.9115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查没有mask的对不对\n",
    "model1 = MultiHeadAttention(5, 2).to(device)\n",
    "input1 = torch.randn(6,5).to(device)\n",
    "y1= model1(input1,input1,input1)\n",
    "print(y1)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1460, -0.8055,  0.5507, -0.5601, -0.3235],\n",
      "        [-0.2116, -0.8053,  0.6204, -0.6045, -0.5233],\n",
      "        [-0.1544, -0.9438,  0.5728, -0.6413, -0.2945],\n",
      "        [-0.0503, -0.8133,  0.4497, -0.4995, -0.0290],\n",
      "        [-0.0012, -0.8401,  0.4000, -0.4808,  0.1312],\n",
      "        [ 0.0013, -0.7856,  0.3921, -0.4493,  0.1174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查有mask的对不对\n",
    "model1 = MultiHeadAttention(5, 2).to(device)\n",
    "input1 = torch.randn(6,5).to(device)\n",
    "y1 = model1(input1,input1,input1,sequece_mask(input1))\n",
    "print(y1)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "位置编码，讲解见后，这里仅给出公式以及这个公式为什么可行：\n",
    "$$PE_{(pos,2*i)} = sin(pos/{10000^{2i/d_{model}}})$$\n",
    "$$PE_{(pos,2*i+1)} = cos(pos/{10000^{2i/d_{model}}})$$\n",
    "这所以可行，是因为这不仅可以表示绝对位置，也可以表示相对位置，$sin(x+y)=sin(x)cos(y)+cos(x)sin(y)$，这意味着$PE(pos+k)$可以用$PE(pos)$和$PE(k)$来表示，故可以表示相对位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, max_len, word_size):\n",
    "        super(PositionEncoding, self).__init__()\n",
    "        self.position_mat = torch.tensor([[pos/np.power(10000,i//2*2/word_size) for i in range(word_size)] for pos in range(max_len)], \\\n",
    "                                        dtype = torch.float32).to(device)\n",
    "        self.position_mat[:,0::2] = torch.sin(self.position_mat[:,0::2])\n",
    "        self.position_mat[:,1::2] = torch.cos(self.position_mat[:,1::2])\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input + self.position_mat[0:input.size(-2),0:input.size(-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](transformer.jpg)\n",
    "embedded: len \\* word_size 这里面需要考虑位置的影响，不然之前那样不考虑位置是不科学的，这个就是有一种奇特的方法加上一个向量。为什么是加呢？\n",
    "可以这样理解：把原来的input延长，补一个位置one-hot变量，那么乘一个矩阵压到这么多维，可以相等于加一个矩阵。embedding的格式\n",
    "就是把input的每个元素都扩展成word_size维的向量，它的两个重要参数第一个是字典大小，第二个是word_size。后面那个参数padding_idx=0表示遇到这个数时生成全为0的向量，比如你输入为了补齐，补了一些0(这份代码补的是2)，这些啥用都没有，就直接生成全0就好了\n",
    "output: len \\* word_size  \n",
    "output2: len \\* word_size  \n",
    "图中每一个的意义： \n",
    "n:首先这个是进行了多次，原论文是6次，本次本着性能不足的原因，就进行一次，若要多次，可把这个封装成一个类，在encodertran调多次即可。  \n",
    "add:就是input+output，加的目的是使梯度>1，防止梯度消失   \n",
    "norm:就是layernormalization  \n",
    "feed forward:就是一个最普通前馈式神经网络，为什么要接这个我也不明白。网上有大佬说接这个是为了使更有效（expressiveness，不知道咋翻译），理由是\n",
    "前面的都是线性的，而这个可以带来了一些非线性的混合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization归一化：使数据的均值和方差变成指定的数，方便学习。\n",
    "![avatar](layernorm.jpg)\n",
    "那个E是均值的意思，Var是方差的意思，$\\gamma$是新的方差，$\\beta$是新的均值  \n",
    "layerNormalization就是把一个数据自身的所有特征进行normalization，而batchNormalization就是把一个batch的所有数据的同一个特征拿来normalization  \n",
    "至于为什么要有$\\gamma$$\\beta$，网上大佬的解释是使他具有capacity，比如如果你后接了一个ReLU,没这个的话一半的输入都输出0，就太不合理了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTran(nn.Module):\n",
    "    #word_number是指字典大小，word_size是embedding的产生出来的size,hidden_size就是multiheadAttention中的hidden_size\n",
    "    #ff_size就是那个前馈式神经网络的隐藏层，max_len就是句子的最长长度，是用来处理位置向量的\n",
    "    def __init__(self, word_number, word_size = 256, hidden_size = 380, ff_size = 400, max_len = MAX_LEN):\n",
    "        super(EncoderTran, self).__init__()\n",
    "        self.word_size = word_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ff_size = ff_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(word_number, word_size)\n",
    "        self.position_mat = PositionEncoding(max_len, word_size)\n",
    "        self.multi_head_attention = MultiHeadAttention(word_size,hidden_size)\n",
    "        self.layernorm1 = nn.LayerNorm(word_size)#里面直接填特征数就可以了，输入len * 特征数就可以了\n",
    "        self.ffn_linear1 = nn.Linear(word_size, ff_size)\n",
    "        self.ffn_linear2 = nn.Linear(ff_size,word_size)\n",
    "        self.layernorm2 = nn.LayerNorm(word_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        embedded =  self.position_mat(self.embedding(input))\n",
    "        #这个mask会自动广播，可以结合图看，只需要使得attention矩阵涉及0的竖行为0就可以了，\n",
    "        #因为横行一是不影响，aij才表示j位置对i位置的attention,只要使添0的地方对有内容的不影响就行了\n",
    "        #二是反正softmax前都全为0，即使写出了-inf一是一样的\n",
    "        output = self.multi_head_attention(embedded, embedded, embedded)\n",
    "        output = self.layernorm1(output + embedded)\n",
    "        output2 = self.ffn_linear2(F.relu(self.ffn_linear1(output)))\n",
    "        output2 = self.layernorm2(output2+output)\n",
    "        return output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5822,  1.5830, -1.2447, -0.4147,  0.6586],\n",
      "        [ 1.1806,  0.3597, -0.0047,  0.3041, -1.8397],\n",
      "        [-0.6398, -0.9151, -0.0357,  1.9104, -0.3198],\n",
      "        [-1.1772, -0.7396,  1.6711,  0.4723, -0.2266],\n",
      "        [ 0.4121,  0.4745,  0.2042, -1.9540,  0.8632],\n",
      "        [-1.0488,  1.6597, -0.0704,  0.4349, -0.9753],\n",
      "        [-1.5248,  0.2272, -0.0185,  1.5953, -0.2793],\n",
      "        [ 0.9337,  0.5870,  0.1316,  0.2696, -1.9219]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查对不对\n",
    "model1 = EncoderTran(10, 5, 4, 3, 9).to(device)#小细节，测试的时候不要让维度有相同的数，这样可以检查维度正不正确\n",
    "input1 = torch.tensor([1,2,7,8,0,9,7,2]).to(device)\n",
    "y1 = model1(input1)\n",
    "print(y1)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：此处，我们让输出和输入长度在训练时都是相同的，方便以后改成可以不一个一个输入，一个batch一个batch输入的情况，在第二个attention(即encoder-decoder attention）那里，注意维度，下面用1指代input，2用来output指代翻译出来的句子。  \n",
    "matq: len2 \\* word_size  \n",
    "matk: len1 \\* word_size  \n",
    "matv: len1 \\* word_size  \n",
    "attention: len2 \\* len1  \n",
    "output2: len2 \\* word_size  \n",
    "此处已经不需要mask了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTran(nn.Module):\n",
    "    def __init__(self,  word_number, word_size = 256, hidden_size = 380, ff_size = 400, max_len = MAX_LEN):\n",
    "        super(DecoderTran, self).__init__()\n",
    "        self.word_size = word_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ff_size = ff_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(word_number, word_size)\n",
    "        self.position_mat = PositionEncoding(max_len, word_size)\n",
    "        \n",
    "        self.multi_head_attention1 = MultiHeadAttention(word_size,hidden_size)\n",
    "        self.layernorm1 = nn.LayerNorm(word_size)\n",
    "        \n",
    "        self.multi_head_attention2 = MultiHeadAttention(word_size,hidden_size)#调用这个的时候确实padding_mask想不清楚，不管了\n",
    "        self.layernorm2 = nn.LayerNorm(word_size)\n",
    "        \n",
    "        self.ffn_linear1 = nn.Linear(word_size, ff_size)\n",
    "        self.ffn_linear2 = nn.Linear(ff_size,word_size)\n",
    "        self.layernorm2 = nn.LayerNorm(word_size)\n",
    "        \n",
    "        self.ans_linear = nn.Linear(word_size,word_number)\n",
    "    \n",
    "    def forward(self, input, enc_output):\n",
    "        embedded =  self.position_mat(self.embedding(input))\n",
    "        output = self.multi_head_attention1(embedded, embedded, embedded, sequece_mask(embedded))\n",
    "        output = self.layernorm1(output + embedded)\n",
    "        \n",
    "        output2 = self.multi_head_attention2(output, enc_output, enc_output)#注意顺序\n",
    "        output2 = self.layernorm2(output2 + output)\n",
    "        \n",
    "        output3 = self.ffn_linear2(F.relu(self.ffn_linear1(output2)))\n",
    "        output3 = self.layernorm2(output3+output2)\n",
    "        \n",
    "        output4 = F.log_softmax(self.ans_linear(output3),dim=1)\n",
    "        return output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3830, -1.8019, -2.7140, -2.1421, -2.6841, -2.7553, -2.6352, -2.9539,\n",
      "         -2.4179, -2.8876],\n",
      "        [-2.0390, -2.5321, -3.3031, -1.3637, -2.7269, -2.0568, -2.0302, -3.0295,\n",
      "         -2.3025, -3.6913],\n",
      "        [-2.7550, -3.1896, -2.8502, -1.2424, -2.5871, -1.8859, -2.6350, -2.4086,\n",
      "         -2.2358, -2.9343],\n",
      "        [-2.5563, -2.8003, -3.0144, -1.1578, -2.8635, -1.8502, -2.6806, -2.5780,\n",
      "         -2.3544, -3.1081],\n",
      "        [-1.7409, -2.0272, -2.7732, -1.5226, -2.7958, -2.5577, -2.8762, -2.8092,\n",
      "         -2.5032, -2.5856]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查对不对\n",
    "model1 = EncoderTran(10, 5, 4, 3, 9).to(device)#小细节，测试的时候不要让维度有相同的数，这样可以检查维度正不正确\n",
    "input1 = torch.tensor([1,2,7,8,3,9,7,2,0]).to(device)\n",
    "y1 = model1(input1)\n",
    "\n",
    "model2 = DecoderTran(10, 5, 4, 3, 9).to(device)\n",
    "input2 = torch.tensor([3,5,7,8,3]).to(device)\n",
    "y2 = model2(input2, y1)\n",
    "print(y2)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    #indexes.append(EOS_token),前面添加了\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1)#这里把它变成了一个向量\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('SOS vous abusez de votre autorite . EOS', 'SOS you are abusing your authority . EOS')\n",
      "(tensor([   0,  118, 3859,  101,  645, 3404,    5,    1], device='cuda:0'), tensor([   0,  129,  124, 2415,  350, 2093,    4,    1], device='cuda:0'))\n",
      "('SOS vous n etes pas censee nager ici . EOS', 'SOS you aren t supposed to swim here . EOS')\n",
      "(tensor([   0,  118,  245,  214,  246, 4028, 1409,   64,    5,    1],\n",
      "       device='cuda:0'), tensor([   0,  129,  564,  538, 1942,  532,  762,   46,    4,    1],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "#测试：\n",
    "print(input_lang.word2index[\"SOS\"])\n",
    "pair=random.choice(pairs)\n",
    "print(pair)\n",
    "print(tensorsFromPair(pair))\n",
    "pair=random.choice(pairs)\n",
    "print(pair)\n",
    "print(tensorsFromPair(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数每次是在拿一个句子进行训练，句子在之前已经补足\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "\n",
    "    #清空梯度\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = encoder(input_tensor)\n",
    "    \n",
    "    decoder_outputs = decoder(target_tensor, encoder_outputs)\n",
    "    loss = criterion(decoder_outputs[0:-1], target_tensor[1:])\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m,s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里才是总的训练\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0].to(device)\n",
    "        target_tensor = training_pair[1].to(device)\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))\n",
    "        \n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0m 23s (- 3m 27s) (1000 10%) 0.4236\n",
      "0m 47s (- 3m 10s) (2000 20%) 0.3442\n",
      "1m 12s (- 2m 49s) (3000 30%) 0.3241\n",
      "1m 37s (- 2m 26s) (4000 40%) 0.3054\n",
      "2m 2s (- 2m 2s) (5000 50%) 0.2961\n",
      "2m 27s (- 1m 38s) (6000 60%) 0.2824\n",
      "2m 53s (- 1m 14s) (7000 70%) 0.2707\n",
      "3m 18s (- 0m 49s) (8000 80%) 0.2609\n",
      "3m 44s (- 0m 24s) (9000 90%) 0.2546\n",
      "4m 9s (- 0m 0s) (10000 100%) 0.2461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(device)\n",
    "encoder1 = EncoderTran(input_lang.n_words).to(device)\n",
    "decoder1 = DecoderTran(output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 10000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 36s (- 59m 39s) (1000 1%) 0.2388\n",
      "0m 57s (- 47m 11s) (2000 2%) 0.2302\n",
      "1m 18s (- 42m 29s) (3000 3%) 0.2213\n",
      "1m 39s (- 39m 59s) (4000 4%) 0.2170\n",
      "2m 1s (- 38m 26s) (5000 5%) 0.2070\n",
      "2m 22s (- 37m 19s) (6000 6%) 0.2061\n",
      "2m 44s (- 36m 22s) (7000 7%) 0.2036\n",
      "3m 6s (- 35m 42s) (8000 8%) 0.1929\n",
      "3m 27s (- 35m 2s) (9000 9%) 0.1930\n",
      "3m 49s (- 34m 21s) (10000 10%) 0.1810\n",
      "4m 10s (- 33m 46s) (11000 11%) 0.1832\n",
      "4m 32s (- 33m 15s) (12000 12%) 0.1730\n",
      "4m 53s (- 32m 45s) (13000 13%) 0.1730\n",
      "5m 14s (- 32m 14s) (14000 14%) 0.1721\n",
      "5m 36s (- 31m 46s) (15000 15%) 0.1649\n",
      "5m 58s (- 31m 19s) (16000 16%) 0.1536\n",
      "6m 19s (- 30m 52s) (17000 17%) 0.1534\n",
      "6m 40s (- 30m 26s) (18000 18%) 0.1487\n",
      "7m 2s (- 29m 59s) (19000 19%) 0.1424\n",
      "7m 23s (- 29m 33s) (20000 20%) 0.1413\n",
      "7m 44s (- 29m 9s) (21000 21%) 0.1435\n",
      "8m 6s (- 28m 44s) (22000 22%) 0.1390\n",
      "8m 27s (- 28m 19s) (23000 23%) 0.1321\n",
      "8m 49s (- 27m 56s) (24000 24%) 0.1327\n",
      "9m 11s (- 27m 33s) (25000 25%) 0.1288\n",
      "9m 32s (- 27m 9s) (26000 26%) 0.1201\n",
      "9m 54s (- 26m 48s) (27000 27%) 0.1204\n",
      "10m 16s (- 26m 25s) (28000 28%) 0.1177\n",
      "10m 38s (- 26m 3s) (29000 28%) 0.1206\n",
      "10m 59s (- 25m 39s) (30000 30%) 0.1058\n",
      "11m 21s (- 25m 15s) (31000 31%) 0.1083\n",
      "11m 42s (- 24m 53s) (32000 32%) 0.1043\n",
      "12m 3s (- 24m 29s) (33000 33%) 0.1048\n",
      "12m 25s (- 24m 6s) (34000 34%) 0.1040\n",
      "12m 47s (- 23m 44s) (35000 35%) 0.0978\n",
      "13m 8s (- 23m 21s) (36000 36%) 0.0991\n",
      "13m 30s (- 22m 59s) (37000 37%) 0.0962\n",
      "13m 51s (- 22m 37s) (38000 38%) 0.0933\n",
      "14m 13s (- 22m 14s) (39000 39%) 0.0871\n",
      "14m 35s (- 21m 52s) (40000 40%) 0.0929\n",
      "14m 55s (- 21m 29s) (41000 41%) 0.0924\n",
      "15m 17s (- 21m 6s) (42000 42%) 0.0867\n",
      "15m 39s (- 20m 44s) (43000 43%) 0.0846\n",
      "16m 0s (- 20m 22s) (44000 44%) 0.0828\n",
      "16m 21s (- 19m 59s) (45000 45%) 0.0820\n",
      "16m 43s (- 19m 37s) (46000 46%) 0.0812\n",
      "17m 4s (- 19m 15s) (47000 47%) 0.0769\n",
      "17m 26s (- 18m 53s) (48000 48%) 0.0689\n",
      "17m 47s (- 18m 31s) (49000 49%) 0.0737\n",
      "18m 10s (- 18m 10s) (50000 50%) 0.0652\n",
      "18m 31s (- 17m 47s) (51000 51%) 0.0708\n",
      "18m 52s (- 17m 25s) (52000 52%) 0.0704\n",
      "19m 14s (- 17m 3s) (53000 53%) 0.0662\n",
      "19m 35s (- 16m 41s) (54000 54%) 0.0656\n",
      "19m 57s (- 16m 19s) (55000 55%) 0.0639\n",
      "20m 19s (- 15m 58s) (56000 56%) 0.0654\n",
      "20m 40s (- 15m 35s) (57000 56%) 0.0625\n",
      "21m 2s (- 15m 14s) (58000 57%) 0.0606\n",
      "21m 23s (- 14m 51s) (59000 59%) 0.0603\n",
      "21m 44s (- 14m 29s) (60000 60%) 0.0604\n",
      "22m 5s (- 14m 7s) (61000 61%) 0.0584\n",
      "22m 27s (- 13m 45s) (62000 62%) 0.0564\n",
      "22m 48s (- 13m 23s) (63000 63%) 0.0568\n",
      "23m 9s (- 13m 1s) (64000 64%) 0.0589\n",
      "23m 31s (- 12m 39s) (65000 65%) 0.0548\n",
      "23m 53s (- 12m 18s) (66000 66%) 0.0538\n",
      "24m 14s (- 11m 56s) (67000 67%) 0.0492\n",
      "24m 36s (- 11m 34s) (68000 68%) 0.0469\n",
      "24m 58s (- 11m 13s) (69000 69%) 0.0482\n",
      "25m 20s (- 10m 51s) (70000 70%) 0.0479\n",
      "25m 41s (- 10m 29s) (71000 71%) 0.0489\n",
      "26m 3s (- 10m 7s) (72000 72%) 0.0478\n",
      "26m 24s (- 9m 46s) (73000 73%) 0.0447\n",
      "26m 46s (- 9m 24s) (74000 74%) 0.0458\n",
      "27m 8s (- 9m 2s) (75000 75%) 0.0437\n",
      "27m 29s (- 8m 40s) (76000 76%) 0.0423\n",
      "27m 51s (- 8m 19s) (77000 77%) 0.0420\n",
      "28m 12s (- 7m 57s) (78000 78%) 0.0452\n",
      "28m 33s (- 7m 35s) (79000 79%) 0.0408\n",
      "28m 54s (- 7m 13s) (80000 80%) 0.0407\n",
      "29m 15s (- 6m 51s) (81000 81%) 0.0394\n",
      "29m 36s (- 6m 30s) (82000 82%) 0.0415\n",
      "29m 58s (- 6m 8s) (83000 83%) 0.0382\n",
      "30m 19s (- 5m 46s) (84000 84%) 0.0392\n",
      "30m 41s (- 5m 24s) (85000 85%) 0.0372\n",
      "31m 2s (- 5m 3s) (86000 86%) 0.0379\n",
      "31m 24s (- 4m 41s) (87000 87%) 0.0344\n",
      "31m 45s (- 4m 19s) (88000 88%) 0.0365\n",
      "32m 6s (- 3m 58s) (89000 89%) 0.0355\n",
      "32m 28s (- 3m 36s) (90000 90%) 0.0348\n",
      "32m 49s (- 3m 14s) (91000 91%) 0.0341\n",
      "33m 10s (- 2m 53s) (92000 92%) 0.0333\n",
      "33m 32s (- 2m 31s) (93000 93%) 0.0326\n",
      "33m 54s (- 2m 9s) (94000 94%) 0.0321\n",
      "34m 15s (- 1m 48s) (95000 95%) 0.0320\n",
      "34m 35s (- 1m 26s) (96000 96%) 0.0305\n",
      "34m 57s (- 1m 4s) (97000 97%) 0.0304\n",
      "35m 18s (- 0m 43s) (98000 98%) 0.0309\n",
      "35m 40s (- 0m 21s) (99000 99%) 0.0341\n",
      "36m 0s (- 0m 0s) (100000 100%) 0.0323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 100000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length = MAX_LEN):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_outputs = encoder(input_tensor)\n",
    "    \n",
    "        decoder_input = torch.tensor([0], device = device)\n",
    "        \n",
    "        decoded_words = []\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output = decoder(decoder_input, encoder_outputs)\n",
    "            topv, topi = decoder_output[di].data.topk(1)\n",
    "            #print(decoder_output[di])\n",
    "            #print(topv)\n",
    "            #print(topi)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            decoder_input = torch.cat((decoder_input, torch.tensor([topi.item()], device = device)))\n",
    "            \n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS elle est un tres bon professeur . EOS\n",
      "= SOS she is a very good teacher . EOS\n",
      "< she is a very good at you . <EOS>\n",
      "\n",
      "> SOS je suis de votre cote . EOS\n",
      "= SOS i m by your side . EOS\n",
      "< i m your friend . <EOS>\n",
      "\n",
      "> SOS je suis satisfaite de sa performance . EOS\n",
      "= SOS i m pleased with his performance . EOS\n",
      "< i m sure of his . <EOS>\n",
      "\n",
      "> SOS je vieillis . EOS\n",
      "= SOS i m getting old . EOS\n",
      "< i m surprised . <EOS>\n",
      "\n",
      "> SOS ils mettent le paquet . EOS\n",
      "= SOS they are investing a lot . EOS\n",
      "< they re the same . <EOS>\n",
      "\n",
      "> SOS nous en sommes toutes d accord . EOS\n",
      "= SOS we re all agreed on that . EOS\n",
      "< we re all alone . <EOS>\n",
      "\n",
      "> SOS tu es voyant . EOS\n",
      "= SOS you re psychic . EOS\n",
      "< you re doing . <EOS>\n",
      "\n",
      "> SOS vous allez perdre . EOS\n",
      "= SOS you re going to lose . EOS\n",
      "< you re resilient . <EOS>\n",
      "\n",
      "> SOS je suis sure que nous pouvons arranger cela . EOS\n",
      "= SOS i m sure we can work this out . EOS\n",
      "< i m glad i am as you . <EOS>\n",
      "\n",
      "> SOS il est joueur . EOS\n",
      "= SOS he s a gambler . EOS\n",
      "< he is about to go . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
